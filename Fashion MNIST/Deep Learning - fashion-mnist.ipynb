{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "cIg6enKVhhi4"
   },
   "source": [
    "\n",
    "\n",
    "## Deep Learning Coursework **\n",
    "\n",
    "**Description**: Create a code using this template to train a Convolutional Neural Network (CNN) on the fashion MNIST dataset available at https://keras.io/api/datasets/fashion_mnist/ . \n",
    "\n",
    "Fashion MNIST is a dataset of 60,000 28x28 grayscale images of 10 fashion categories, along with a test set of 10,000 images.\n",
    "\n",
    "The dataset should be imported in the code and one sample image should be visualised before applying the model.\n",
    "\n",
    "Define a CNN and comment the chosen parameters of the network. Apply a regularization method (L1, L2 or L1L2). Divide the dataset into training, validation and test set. Obtain the accuracy on the validation set and plot the final results using the data from the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Sd1QGylWZAkA"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 14:31:30.912493: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-24 14:31:30.912526: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# importing of modules for CIFAR-10 CNN \n",
    "# from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.regularizers import l2\n",
    "from keras.regularizers import l1\n",
    "from keras.regularizers import l1_l2\n",
    "\n",
    "# importing of service libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FkERIusYhcK6"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "sample_image = x_train[0]\n",
    "\n",
    "# consider them as float and normalize\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255 \n",
    "x_test /= 255  \n",
    "\n",
    "# we need a 60K x [1 x 28 x 28] shape as input to the CONVNET\n",
    "x_train = x_train.reshape(60000, 28, 28, 1)\n",
    "x_test = x_test.reshape(10000, 28, 28, 1)\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = utils.to_categorical(y_train,10 )\n",
    "y_test = utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Define the number of folds\n",
    "k = 5\n",
    "\n",
    "# Split the data into k folds\n",
    "kfold = KFold(k, shuffle=True, random_state=0)\n",
    "\n",
    "# concatenate the data in preparation for the kfold split\n",
    "combined_x_data = np.concatenate((x_train, x_test))\n",
    "combined_y_data = np.concatenate((y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "tV9PO1GBl5_6",
    "outputId": "b5b62043-fbe0-419a-d718-9c88c5b2787c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample_image)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bTTrIN_nnDWK",
    "outputId": "eadb0ede-e1c5-40e2-a7a5-754b6e004da3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               401536    \n",
      "                                                                 \n",
      " activation (Activation)     (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 429,258\n",
      "Trainable params: 429,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 15:42:47.481231: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-23 15:42:47.481270: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-23 15:42:47.481293: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jupyter): /proc/driver/nvidia/version does not exist\n",
      "2023-02-23 15:42:47.481554: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# network and training parameters\n",
    "N_EPOCH = 20 \n",
    "BATCH_SIZE = 128 # number of samples to be processed before updating the model\n",
    "VERBOSE = 1 \n",
    "OPTIMIZER = Adam()\n",
    "\n",
    "IMG_ROWS, IMG_COLS = 28, 28 # input  dimensions of each MNIST image\n",
    "N_CLASSES = 10  # number of fashion categories\n",
    "INPUT_SHAPE = (IMG_ROWS, IMG_COLS, 1) # input shape to be fed into the convolutional layers\n",
    "\n",
    "# Images have to be reshaped from matrices to a single long row\n",
    "RESHAPED = 784\n",
    "\n",
    "# Instantiate a Keras model with sequential layers\n",
    "model = Sequential()\n",
    "\n",
    "# The first convolutional layer has zero padding so as to not ignore the edges (rows & columns) of the images\n",
    "# Using relu as it is fast to compute\n",
    "model.add(Conv2D(32, kernel_size=3, padding=\"same\", input_shape=INPUT_SHAPE, activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "\n",
    "# Second convolutional layer\n",
    "model.add(Conv2D(64, kernel_size=3, padding=\"same\", input_shape=INPUT_SHAPE, activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "\n",
    "# Flatten all the layers to be added into the \n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, kernel_regularizer=l2(0.01))) \n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(64, kernel_regularizer=l2(0.01)))\n",
    "model.add(Dense(N_CLASSES)) # 10 different fashion categories\n",
    "model.add(Activation('softmax')) # using the activation softmax as it is a multiclass classification problem\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "urupEGOFooUz",
    "outputId": "cd2a111e-ce22-4392-ec21-5c55020d9809"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "438/438 [==============================] - 16s 35ms/step - loss: 1.2051 - accuracy: 0.7966\n",
      "Epoch 2/20\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6345 - accuracy: 0.8522\n",
      "Epoch 3/20\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5238 - accuracy: 0.8660\n",
      "Epoch 4/20\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4665 - accuracy: 0.8754\n",
      "Epoch 5/20\n",
      "438/438 [==============================] - 14s 32ms/step - loss: 0.4372 - accuracy: 0.8802\n",
      "Epoch 6/20\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4158 - accuracy: 0.8857\n",
      "Epoch 7/20\n",
      "438/438 [==============================] - 14s 32ms/step - loss: 0.3966 - accuracy: 0.8904\n",
      "Epoch 8/20\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3817 - accuracy: 0.8942\n",
      "Epoch 9/20\n",
      "438/438 [==============================] - 14s 32ms/step - loss: 0.3714 - accuracy: 0.8964\n",
      "Epoch 10/20\n",
      "438/438 [==============================] - 14s 31ms/step - loss: 0.3631 - accuracy: 0.8998\n",
      "Epoch 11/20\n",
      "438/438 [==============================] - 11s 26ms/step - loss: 0.3520 - accuracy: 0.9025\n",
      "Epoch 12/20\n",
      "438/438 [==============================] - 11s 24ms/step - loss: 0.3425 - accuracy: 0.9046\n",
      "Epoch 13/20\n",
      "438/438 [==============================] - 11s 25ms/step - loss: 0.3406 - accuracy: 0.9050\n",
      "Epoch 14/20\n",
      "438/438 [==============================] - 11s 24ms/step - loss: 0.3334 - accuracy: 0.9068\n",
      "Epoch 15/20\n",
      "438/438 [==============================] - 11s 26ms/step - loss: 0.3259 - accuracy: 0.9097\n",
      "Epoch 16/20\n",
      "438/438 [==============================] - 11s 24ms/step - loss: 0.3216 - accuracy: 0.9105\n",
      "Epoch 17/20\n",
      "438/438 [==============================] - 11s 24ms/step - loss: 0.3189 - accuracy: 0.9124\n",
      "Epoch 18/20\n",
      "438/438 [==============================] - 10s 24ms/step - loss: 0.3159 - accuracy: 0.9126\n",
      "Epoch 19/20\n",
      "438/438 [==============================] - 11s 25ms/step - loss: 0.3096 - accuracy: 0.9132\n",
      "Epoch 20/20\n",
      "438/438 [==============================] - 11s 25ms/step - loss: 0.3094 - accuracy: 0.9148\n",
      "438/438 [==============================] - 2s 5ms/step - loss: 0.3189 - accuracy: 0.9121\n",
      "Epoch 1/20\n",
      "438/438 [==============================] - 11s 25ms/step - loss: 0.3067 - accuracy: 0.9148\n",
      "Epoch 2/20\n",
      "438/438 [==============================] - 11s 25ms/step - loss: 0.2986 - accuracy: 0.9171\n",
      "Epoch 3/20\n",
      "438/438 [==============================] - 12s 27ms/step - loss: 0.2941 - accuracy: 0.9186\n",
      "Epoch 4/20\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.2916 - accuracy: 0.9204\n",
      "Epoch 5/20\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2888 - accuracy: 0.9213\n",
      "Epoch 6/20\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2895 - accuracy: 0.9204\n",
      "Epoch 7/20\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2865 - accuracy: 0.9214\n",
      "Epoch 8/20\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2848 - accuracy: 0.9219\n",
      "Epoch 9/20\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2817 - accuracy: 0.9227\n",
      "Epoch 10/20\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2769 - accuracy: 0.9243\n",
      "Epoch 11/20\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2779 - accuracy: 0.9241\n",
      "Epoch 12/20\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.2738 - accuracy: 0.9263\n",
      "Epoch 13/20\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.2731 - accuracy: 0.9264\n",
      "Epoch 14/20\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.2692 - accuracy: 0.9273\n",
      "Epoch 15/20\n",
      "438/438 [==============================] - 16s 36ms/step - loss: 0.2676 - accuracy: 0.9276\n",
      "Epoch 16/20\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2683 - accuracy: 0.9278\n",
      "Epoch 17/20\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.2632 - accuracy: 0.9292\n",
      "Epoch 18/20\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.2603 - accuracy: 0.9305\n",
      "Epoch 19/20\n",
      "438/438 [==============================] - 16s 38ms/step - loss: 0.2597 - accuracy: 0.9307\n",
      "Epoch 20/20\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2599 - accuracy: 0.9303\n",
      "438/438 [==============================] - 3s 8ms/step - loss: 0.3050 - accuracy: 0.9157\n",
      "Epoch 1/20\n",
      "438/438 [==============================] - 18s 41ms/step - loss: 0.2713 - accuracy: 0.9264\n",
      "Epoch 2/20\n",
      "438/438 [==============================] - 18s 42ms/step - loss: 0.2620 - accuracy: 0.9289\n",
      "Epoch 3/20\n",
      "438/438 [==============================] - 18s 42ms/step - loss: 0.2610 - accuracy: 0.9296\n",
      "Epoch 4/20\n",
      "438/438 [==============================] - 19s 43ms/step - loss: 0.2581 - accuracy: 0.9310\n",
      "Epoch 5/20\n",
      "438/438 [==============================] - 19s 42ms/step - loss: 0.2580 - accuracy: 0.9312\n",
      "Epoch 6/20\n",
      "438/438 [==============================] - 19s 43ms/step - loss: 0.2562 - accuracy: 0.9316\n",
      "Epoch 7/20\n",
      "438/438 [==============================] - 19s 43ms/step - loss: 0.2503 - accuracy: 0.9340\n",
      "Epoch 8/20\n",
      "438/438 [==============================] - 19s 42ms/step - loss: 0.2501 - accuracy: 0.9334\n",
      "Epoch 9/20\n",
      "438/438 [==============================] - 18s 42ms/step - loss: 0.2510 - accuracy: 0.9328\n",
      "Epoch 10/20\n",
      "438/438 [==============================] - 18s 42ms/step - loss: 0.2504 - accuracy: 0.9325\n",
      "Epoch 11/20\n",
      "438/438 [==============================] - 19s 42ms/step - loss: 0.2494 - accuracy: 0.9327\n",
      "Epoch 12/20\n",
      "438/438 [==============================] - 19s 43ms/step - loss: 0.2495 - accuracy: 0.9333\n",
      "Epoch 13/20\n",
      "438/438 [==============================] - 20s 45ms/step - loss: 0.2462 - accuracy: 0.9351\n",
      "Epoch 14/20\n",
      "438/438 [==============================] - 19s 43ms/step - loss: 0.2439 - accuracy: 0.9354\n",
      "Epoch 15/20\n",
      "438/438 [==============================] - 18s 42ms/step - loss: 0.2456 - accuracy: 0.9351\n",
      "Epoch 16/20\n",
      "438/438 [==============================] - 18s 42ms/step - loss: 0.2437 - accuracy: 0.9356\n",
      "Epoch 17/20\n",
      "438/438 [==============================] - 17s 38ms/step - loss: 0.2450 - accuracy: 0.9345\n",
      "Epoch 18/20\n",
      "438/438 [==============================] - 16s 37ms/step - loss: 0.2418 - accuracy: 0.9364\n",
      "Epoch 19/20\n",
      "438/438 [==============================] - 18s 42ms/step - loss: 0.2379 - accuracy: 0.9378\n",
      "Epoch 20/20\n",
      "438/438 [==============================] - 18s 41ms/step - loss: 0.2421 - accuracy: 0.9356\n",
      "438/438 [==============================] - 4s 9ms/step - loss: 0.2625 - accuracy: 0.9304\n",
      "Epoch 1/20\n",
      "438/438 [==============================] - 19s 41ms/step - loss: 0.2488 - accuracy: 0.9338\n",
      "Epoch 2/20\n",
      "438/438 [==============================] - 18s 41ms/step - loss: 0.2421 - accuracy: 0.9364\n",
      "Epoch 3/20\n",
      "438/438 [==============================] - 18s 41ms/step - loss: 0.2411 - accuracy: 0.9358\n",
      "Epoch 4/20\n",
      "438/438 [==============================] - 18s 42ms/step - loss: 0.2394 - accuracy: 0.9363\n",
      "Epoch 5/20\n",
      "438/438 [==============================] - 18s 41ms/step - loss: 0.2367 - accuracy: 0.9378\n",
      "Epoch 6/20\n",
      "438/438 [==============================] - 23s 52ms/step - loss: 0.2354 - accuracy: 0.9385\n",
      "Epoch 7/20\n",
      "438/438 [==============================] - 24s 54ms/step - loss: 0.2370 - accuracy: 0.9375\n",
      "Epoch 8/20\n",
      "438/438 [==============================] - 22s 51ms/step - loss: 0.2383 - accuracy: 0.9371\n",
      "Epoch 9/20\n",
      "438/438 [==============================] - 23s 52ms/step - loss: 0.2317 - accuracy: 0.9390\n",
      "Epoch 10/20\n",
      "438/438 [==============================] - 23s 52ms/step - loss: 0.2324 - accuracy: 0.9388\n",
      "Epoch 11/20\n",
      "438/438 [==============================] - 22s 51ms/step - loss: 0.2309 - accuracy: 0.9405\n",
      "Epoch 12/20\n",
      "438/438 [==============================] - 22s 50ms/step - loss: 0.2326 - accuracy: 0.9386\n",
      "Epoch 13/20\n",
      "438/438 [==============================] - 21s 48ms/step - loss: 0.2295 - accuracy: 0.9408\n",
      "Epoch 14/20\n",
      "438/438 [==============================] - 18s 41ms/step - loss: 0.2289 - accuracy: 0.9394\n",
      "Epoch 15/20\n",
      "438/438 [==============================] - 20s 45ms/step - loss: 0.2286 - accuracy: 0.9413\n",
      "Epoch 16/20\n",
      "438/438 [==============================] - 19s 44ms/step - loss: 0.2273 - accuracy: 0.9409\n",
      "Epoch 17/20\n",
      "438/438 [==============================] - 21s 48ms/step - loss: 0.2261 - accuracy: 0.9411\n",
      "Epoch 18/20\n",
      "438/438 [==============================] - 23s 52ms/step - loss: 0.2260 - accuracy: 0.9421\n",
      "Epoch 19/20\n",
      "438/438 [==============================] - 23s 52ms/step - loss: 0.2241 - accuracy: 0.9419\n",
      "Epoch 20/20\n",
      "438/438 [==============================] - 23s 52ms/step - loss: 0.2252 - accuracy: 0.9424\n",
      "438/438 [==============================] - 5s 12ms/step - loss: 0.2805 - accuracy: 0.9229\n",
      "Epoch 1/20\n",
      "438/438 [==============================] - 23s 52ms/step - loss: 0.2359 - accuracy: 0.9381\n",
      "Epoch 2/20\n",
      "438/438 [==============================] - 23s 52ms/step - loss: 0.2287 - accuracy: 0.9404\n",
      "Epoch 3/20\n",
      "438/438 [==============================] - 19s 43ms/step - loss: 0.2256 - accuracy: 0.9408\n",
      "Epoch 4/20\n",
      "438/438 [==============================] - 19s 42ms/step - loss: 0.2267 - accuracy: 0.9402\n",
      "Epoch 5/20\n",
      "438/438 [==============================] - 18s 41ms/step - loss: 0.2248 - accuracy: 0.9420\n",
      "Epoch 6/20\n",
      "438/438 [==============================] - 18s 40ms/step - loss: 0.2233 - accuracy: 0.9423\n",
      "Epoch 7/20\n",
      "438/438 [==============================] - 20s 45ms/step - loss: 0.2234 - accuracy: 0.9424\n",
      "Epoch 8/20\n",
      "438/438 [==============================] - 21s 47ms/step - loss: 0.2195 - accuracy: 0.9440\n",
      "Epoch 9/20\n",
      "438/438 [==============================] - 23s 52ms/step - loss: 0.2216 - accuracy: 0.9430\n",
      "Epoch 10/20\n",
      "438/438 [==============================] - 23s 52ms/step - loss: 0.2185 - accuracy: 0.9447\n",
      "Epoch 11/20\n",
      "438/438 [==============================] - 22s 51ms/step - loss: 0.2187 - accuracy: 0.9439\n",
      "Epoch 12/20\n",
      "438/438 [==============================] - 23s 52ms/step - loss: 0.2182 - accuracy: 0.9442\n",
      "Epoch 13/20\n",
      "438/438 [==============================] - 23s 52ms/step - loss: 0.2153 - accuracy: 0.9454\n",
      "Epoch 14/20\n",
      "438/438 [==============================] - 23s 52ms/step - loss: 0.2166 - accuracy: 0.9457\n",
      "Epoch 15/20\n",
      "438/438 [==============================] - 23s 52ms/step - loss: 0.2180 - accuracy: 0.9447\n",
      "Epoch 16/20\n",
      "438/438 [==============================] - 23s 52ms/step - loss: 0.2146 - accuracy: 0.9472\n",
      "Epoch 17/20\n",
      "438/438 [==============================] - 23s 52ms/step - loss: 0.2152 - accuracy: 0.9464\n",
      "Epoch 18/20\n",
      "438/438 [==============================] - 23s 52ms/step - loss: 0.2111 - accuracy: 0.9482\n",
      "Epoch 19/20\n",
      "438/438 [==============================] - 23s 52ms/step - loss: 0.2132 - accuracy: 0.9455\n",
      "Epoch 20/20\n",
      "438/438 [==============================] - 23s 52ms/step - loss: 0.2112 - accuracy: 0.9482\n",
      "438/438 [==============================] - 5s 12ms/step - loss: 0.2878 - accuracy: 0.9230\n"
     ]
    }
   ],
   "source": [
    "# train and test the model \n",
    "\n",
    "# variables to store the accuracy and losses of the training and testing data\n",
    "histories = []\n",
    "test_accuracies = []\n",
    "test_losses = []\n",
    "\n",
    "# split the data into kfold \n",
    "for i, (train_index, test_index) in enumerate(kfold.split(combined_x_data)):\n",
    "\n",
    "    model.compile(optimizer=OPTIMIZER, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    # train and store the accuracy and loss scores\n",
    "    histories.append(model.fit(combined_x_data[train_index],combined_y_data[train_index], epochs=N_EPOCH, \n",
    "        batch_size=BATCH_SIZE, verbose=VERBOSE))\n",
    "\n",
    "    # test the model and store the results\n",
    "    results = model.evaluate(combined_x_data[test_index], combined_y_data[test_index])\n",
    "    \n",
    "    test_losses.append(results[0])\n",
    "    test_accuracies.append(results[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xESPeCWnpJek"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 cross validation accuracy: 0.8914580345153809\n",
      "Fold 1 cross validation loss: 0.42327538430690764\n",
      "Fold 2 cross validation accuracy: 0.9241383999586106\n",
      "Fold 2 cross validation loss: 0.2786152720451355\n",
      "Fold 3 cross validation accuracy: 0.9331419676542282\n",
      "Fold 3 cross validation loss: 0.2506678394973278\n",
      "Fold 4 cross validation accuracy: 0.9390008926391602\n",
      "Fold 4 cross validation loss: 0.23310305550694466\n",
      "Fold 5 cross validation accuracy: 0.9438803553581238\n",
      "Fold 5 cross validation loss: 0.22000123783946038\n",
      "Average cross validation accuracy: 0.9263239300251007\n",
      "Average cross validation loss: 0.2811325578391552\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each fold and print out the loss and accuracy scores\n",
    "cross_val_accuracies = []\n",
    "cross_val_losses = []\n",
    "for x in range(k):\n",
    "    cross_val_accuracies.append(sum(histories[x].history['accuracy']) / N_EPOCH)\n",
    "    cross_val_losses.append(sum(histories[x].history['loss']) / N_EPOCH)\n",
    "    print(f'Fold {x + 1} cross validation accuracy: { cross_val_accuracies[x] }')\n",
    "    print(f'Fold {x + 1} cross validation loss: { cross_val_losses[x] }')\n",
    "\n",
    "# Obtain the validations \n",
    "average_validation_accuracy = sum(cross_val_accuracies) / k\n",
    "average_validation_loss = sum(cross_val_losses) / k\n",
    "\n",
    "# Print the results\n",
    "print(f'Average cross validation accuracy: {average_validation_accuracy}')\n",
    "print(f'Average cross validation loss: {average_validation_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "WnCeV6qP6xmT"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate x axis labels\n",
    "axis = np.arange(k) + 1\n",
    "\n",
    "# plot testing accuracy\n",
    "labels = [ f'Fold {x + 1}' for x in range(k)]\n",
    "plt.bar(labels, test_accuracies)\n",
    "plt.title('Testing model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('Folds')\n",
    "plt.show()\n",
    " \n",
    "# plot testing loss\n",
    "plt.bar(labels, test_losses)\n",
    "plt.title('Testing model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('Fold')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ImI7busBrCie"
   },
   "source": [
    "Remarks:\n",
    "\n",
    "There was a slight drop in the network's accuracy  when applying regularisation as compared to not applying it. The regularisation used was L2. In addition to the slight drop in network's accuracy, the network's loss also significantly differed as regularisation increases loss to ensure that there is no overfitting. It is expected of regularization method L2 as it forces the model weights to be kept as small as possible, reducing them model's variance but increasing its bias. \n",
    "\n",
    "Overall, the accuracy of the model is quite good with testing and validation accuracy being above 80%. The loss for the validation set and testing are also fairly similar which could mean that the model is currently not overfitting or underfitting. \n",
    "\n",
    "Another way to improve results/performance could be perhaps to add another convolutional layer as this might provide even higher accuracy. Additionally, to further reduce the losses of the model, a different regularization technique could be used such as drop out or combining both l1 and l2 as regularization methods. Further tweaking of L2 hyperparameter could also possibly yield better results. \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "EcSc_1JiqRA3"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "d3e7af04d29b7c7f09156ce72bf463dad5c8b45a218773abf1ffb50277174388"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
